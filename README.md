# Machine Learning Lectures

### Themes to cover:

* Introduction to Probability: Discrete and continuous probability distributions, Likelihood function, Bayes theorem, Limit theorems, Smirnov's theorem and Inverse method for random variables generation, Acceptance-Rejection method for random variables generation, Dependence and Copulas, Entropy;
* Introduction to Machine Learning: Iris dataset for classification and clusterization tasks;
* Chapter 1 - Perceptrons (batch and on-line learning); 
* Chapter 2 - Bayes classifiers; 
* Chapter 3 - Regression classifier and Maximum A Posteriori estimates; 
* Chapter 4 - Mean-Squares estimation, Gradient descent, Gauss-Newton algorithms;
* Chapter 5 - Multilayer Perceptron;
* Chapter 6 - K-Means clustering algorithm and variants;
* Chapter 7 - Kernel methods introduction (kernel trick, kernel classifier, feature space);
* Chapter 8 - Radial-Basis interpolation (a bit of regularization), RBF networks for classification;
* Chapter 9 - Wisdom of crowds and Ensemble learning;
* Chapter 10 - ARIMA (time series analysis) + Kalman filter;
* Chapter 11 - Singular Spectrum Analysis (seasonal time series analysis);
* Chapter 12 - Bayesian Inference;

### Links for datasets:

* scikit-learn.org
* www.kaggle.com
* https://vincentarelbundock.github.io/Rdatasets/datasets.html

### References:

* http://colah.github.io/
